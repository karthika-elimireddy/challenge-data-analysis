# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
file_path = "path_to_your_dataset.csv"  # Update with your dataset's path
df = pd.read_csv(file_path)

### Step 1: Data Cleaning ###

# Remove duplicates
df = df.drop_duplicates()

# Remove leading/trailing spaces in string columns
df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)

# Handle missing values (drop or fill)
missing_values_percentage = df.isnull().mean() * 100
print("Percentage of missing values per column:\n", missing_values_percentage)

# Example: Dropping columns with >50% missing values
df = df.loc[:, missing_values_percentage < 50]

# Fill missing numeric values with median
for col in df.select_dtypes(include=np.number).columns:
    df[col].fillna(df[col].median(), inplace=True)

# Fill missing categorical values with mode
for col in df.select_dtypes(include="object").columns:
    df[col].fillna(df[col].mode()[0], inplace=True)

### Step 2: Data Analysis ###

# Basic dataset overview
print("Number of rows and columns:", df.shape)
print(df.info())
print(df.describe())

# Correlation analysis
plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

# Correlation with price
correlation_with_price = df.corr()["price"].sort_values(ascending=False)
print("Correlation with Price:\n", correlation_with_price)

# Analyze qualitative vs quantitative variables
qualitative_vars = df.select_dtypes(include="object").columns
quantitative_vars = df.select_dtypes(include=np.number).columns
print(f"Qualitative Variables: {qualitative_vars}")
print(f"Quantitative Variables: {quantitative_vars}")

# Transform qualitative variables into numerical values using encoding
df_encoded = pd.get_dummies(df, columns=qualitative_vars, drop_first=True)

# Plot the distribution of prices
plt.figure(figsize=(10, 6))
sns.histplot(df["price"], kde=True, bins=30, color="blue")
plt.title("Price Distribution")
plt.xlabel("Price")
plt.ylabel("Frequency")
plt.show()

### Step 3: Data Interpretation ###

# Plot outliers for price
plt.figure(figsize=(10, 6))
sns.boxplot(data=df, x="price")
plt.title("Outliers in Price")
plt.xlabel("Price")
plt.show()

# Histogram of surface area
plt.figure(figsize=(10, 6))
sns.histplot(df["livingArea"], kde=False, bins=30, color="green")
plt.title("Distribution of Living Area")
plt.xlabel("Living Area")
plt.ylabel("Frequency")
plt.show()

# Most important variables based on correlation
top_features = correlation_with_price.index[:5]
print("Top 5 variables influencing price:", top_features)

# Municipality analysis
def analyze_municipalities(region_filter=None):
    if region_filter:
        region_df = df[df["locality"].str.contains(region_filter, case=False, na=False)]
    else:
        region_df = df
    
    municipality_stats = region_df.groupby("locality").agg(
        avg_price=("price", "mean"),
        median_price=("price", "median"),
        price_per_sqm=("price", lambda x: np.mean(x / region_df["livingArea"]))
    ).sort_values("avg_price", ascending=False)
    
    return municipality_stats

# Most and least expensive municipalities in Belgium
belgium_stats = analyze_municipalities()
print("Most expensive municipalities in Belgium:\n", belgium_stats.head())
print("Least expensive municipalities in Belgium:\n", belgium_stats.tail())

# Most and least expensive municipalities in Wallonia
wallonia_stats = analyze_municipalities(region_filter="Wallonia")
print("Most expensive municipalities in Wallonia:\n", wallonia_stats.head())
print("Least expensive municipalities in Wallonia:\n", wallonia_stats.tail())

# Most and least expensive municipalities in Flanders
flanders_stats = analyze_municipalities(region_filter="Flanders")
print("Most expensive municipalities in Flanders:\n", flanders_stats.head())
print("Least expensive municipalities in Flanders:\n", flanders_stats.tail())
